{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an AI with ConvNet for Reversi Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "Contributor: Zukang Yang\n",
    "\n",
    "-------------------------------------------\n",
    "\n",
    "In this project, we are learning to play Reversi (black player's perspective) with convolutional neural network. \n",
    "\n",
    "### Generating data: \n",
    "The Reversi data are generated in Matlab. I modified Professor Long Chen's generatedata.m to be able to generate the data with AI tree-searched algorithm and saved them as text files.\n",
    "\n",
    "### What do the data look like?\n",
    "The data consist of \n",
    "\n",
    "**1).** a 8x8 matrix resembling the Reversi board game with 1 to be black stone, -1 to be white stone and 0 to be empty; \n",
    "\n",
    "**2).** a vector containing the next best move given the current stone locations, i.e. a positive value is the next best move for the black player; a negative value is the next best move for the white player (each element is range from 0 to 64 -- 0 means pass and 1~64 is the index for the next best move);\n",
    "\n",
    "**3).** a 8x8 matrix recording all available moves for the current player (1:black or -1:white).\n",
    "\n",
    "Training set: 90,000 moves\n",
    "\n",
    "Test set: 6000 moves\n",
    " \n",
    "### How to process the data generated from Matlab?\n",
    "Refering to IV, part B in page 3 of *Learning to Play Othello with Deep Neural Networks*, the reversi_data file contains the Reversi data, i.e. 8x8 matrices. I split each matrix into two matrices of the same size with each of new matrices containing only the black or white stones. Then, combine with the data from the valid_moves file, we can create a dataset of a (n, 8, 8, 3) array which is the training data for the CNN model. Last, the next_move file provides classification data for the CNN model. \n",
    "\n",
    "### Structure of the CNN:\n",
    "First CNN layer: 64 3x3 kernels\n",
    "\n",
    "Second CNN layer: 128 3x3 kernels\n",
    "\n",
    "One 2x2 maxpooling layer\n",
    "\n",
    "One fully-connected layer with 128 perceptrons\n",
    "\n",
    "One output layer with 65 perceptrons\n",
    "\n",
    "\n",
    "### Reference\n",
    "* [Professor Long Chen's Github page including all necessary codes for generating Reversi data in Matlab](https://github.com/lyc102/reversi).\n",
    "* [Reversi - Wikipedia](https://en.wikipedia.org/wiki/Reversi).\n",
    "* [Learning to Play Othello with Deep Neural Networks](https://arxiv.org/pdf/1711.06583.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import relevant packages"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install tensorflow  # run this cell if you haven't installed tensorflow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install keras       # run this cell if you haven't installed keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split  # validation\n",
    "\n",
    "# for constructing CNN\n",
    "from keras.utils import to_categorical                # one-hot encode target column\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversi = np.loadtxt('reversi_data.txt').reshape(-1, 64)   # Reversi data\n",
    "move = np.loadtxt('next_move.txt')                         # next move\n",
    "valid = np.loadtxt('valid_moves.txt').reshape(-1, 64)      # next valid moves\n",
    "\n",
    "reversi_t = np.loadtxt('reversi_data_test.txt').reshape(-1, 64)   \n",
    "move_t = np.loadtxt('next_move_test.txt')                         \n",
    "valid_t = np.loadtxt('valid_moves_test.txt').reshape(-1, 64)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player(data, valid, label, turn='black'):\n",
    "    '''Return a tuple of three numpy arrays containing the reversi data for the specified player.\n",
    "    turn -- 'black' or 'white' '''\n",
    "    if turn == 'black':\n",
    "        cond = np.where(label>=0)[0]\n",
    "        idx = [i for i in cond if i%2==0]\n",
    "        return (data[idx], valid[idx], label[idx])\n",
    "    \n",
    "    elif turn == 'white':\n",
    "        cond = np.where(label<=0)[0]\n",
    "        idx = [i for i in cond if i%2==1]\n",
    "        return (data[idx], valid[idx], label[idx])\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Please enter either black or white.')\n",
    "\n",
    "\n",
    "def black_and_white(data):\n",
    "    '''Return a tuple of numpy array that separate black pieces from white pieces.\n",
    "    input -- the reversi data.'''\n",
    "    black = np.zeros(data.shape)\n",
    "    white = np.zeros(data.shape)\n",
    "    \n",
    "    black = (data==1.0)*1.0\n",
    "    white = (data==-1.0)*1.0\n",
    "    return (black, white)\n",
    "\n",
    "\n",
    "def concatenate(black, white, valid_moves):\n",
    "    '''Return a 4d array for training CNN model.'''\n",
    "    n = black.shape[0]   # n rows\n",
    "    black = black.reshape(n, 8, 8, 1)\n",
    "    white = white.reshape(n, 8, 8, 1)\n",
    "    valid_moves = valid_moves.reshape(n, 8, 8, 1)\n",
    "    \n",
    "    return np.concatenate((black, white, valid_moves), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- training set -----------------------\n",
    "game, v_moves, n_moves = player(reversi, valid, move)   # v_moves -- valid moves; n_move -- next moves\n",
    "black, white = black_and_white(game)                    # split each board into only black and only white\n",
    "\n",
    "train = concatenate(black, white, v_moves)              # training data\n",
    "y_train = to_categorical(n_moves)                             # labels\n",
    "\n",
    "# ---------------- test set --------------------------\n",
    "game_t, v_moves_t, n_moves_t = player(reversi_t, valid_t, move_t)\n",
    "black_t, white_t = black_and_white(game_t)\n",
    "\n",
    "X_test = concatenate(black_t, white_t, v_moves_t)\n",
    "y_test = to_categorical(n_moves_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38250 samples, validate on 6750 samples\n",
      "Epoch 1/48\n",
      "38250/38250 [==============================] - 11s 283us/step - loss: 2.6056 - acc: 0.3269 - val_loss: 1.4228 - val_acc: 0.6135\n",
      "Epoch 2/48\n",
      "38250/38250 [==============================] - 11s 275us/step - loss: 1.3158 - acc: 0.6246 - val_loss: 0.8666 - val_acc: 0.7470\n",
      "Epoch 3/48\n",
      "38250/38250 [==============================] - 10s 267us/step - loss: 0.9654 - acc: 0.7115 - val_loss: 0.6850 - val_acc: 0.7929\n",
      "Epoch 4/48\n",
      "38250/38250 [==============================] - 10s 271us/step - loss: 0.7994 - acc: 0.7541 - val_loss: 0.5784 - val_acc: 0.8199\n",
      "Epoch 5/48\n",
      "38250/38250 [==============================] - 10s 272us/step - loss: 0.6983 - acc: 0.7794 - val_loss: 0.5160 - val_acc: 0.8357\n",
      "Epoch 6/48\n",
      "38250/38250 [==============================] - 10s 271us/step - loss: 0.6298 - acc: 0.7995 - val_loss: 0.4720 - val_acc: 0.8441\n",
      "Epoch 7/48\n",
      "38250/38250 [==============================] - 10s 265us/step - loss: 0.5749 - acc: 0.8141 - val_loss: 0.4452 - val_acc: 0.8492\n",
      "Epoch 8/48\n",
      "38250/38250 [==============================] - 10s 264us/step - loss: 0.5377 - acc: 0.8244 - val_loss: 0.4223 - val_acc: 0.8579\n",
      "Epoch 9/48\n",
      "38250/38250 [==============================] - 10s 264us/step - loss: 0.4993 - acc: 0.8325 - val_loss: 0.4086 - val_acc: 0.8624\n",
      "Epoch 10/48\n",
      "38250/38250 [==============================] - 10s 263us/step - loss: 0.4736 - acc: 0.8402 - val_loss: 0.4061 - val_acc: 0.8600\n",
      "Epoch 11/48\n",
      "38250/38250 [==============================] - 10s 260us/step - loss: 0.4461 - acc: 0.8479 - val_loss: 0.3883 - val_acc: 0.8689\n",
      "Epoch 12/48\n",
      "38250/38250 [==============================] - 10s 259us/step - loss: 0.4264 - acc: 0.8524 - val_loss: 0.3832 - val_acc: 0.8668\n",
      "Epoch 13/48\n",
      "38250/38250 [==============================] - 10s 256us/step - loss: 0.4177 - acc: 0.8526 - val_loss: 0.3741 - val_acc: 0.8704\n",
      "Epoch 14/48\n",
      "38250/38250 [==============================] - 10s 257us/step - loss: 0.3957 - acc: 0.8593 - val_loss: 0.3752 - val_acc: 0.8713\n",
      "Epoch 15/48\n",
      "38250/38250 [==============================] - 10s 265us/step - loss: 0.3848 - acc: 0.8629 - val_loss: 0.3747 - val_acc: 0.8699\n",
      "Epoch 16/48\n",
      "38250/38250 [==============================] - 10s 256us/step - loss: 0.3686 - acc: 0.8672 - val_loss: 0.3616 - val_acc: 0.8716\n",
      "Epoch 17/48\n",
      "38250/38250 [==============================] - 10s 252us/step - loss: 0.3610 - acc: 0.8688 - val_loss: 0.3597 - val_acc: 0.8736\n",
      "Epoch 18/48\n",
      "38250/38250 [==============================] - 10s 251us/step - loss: 0.3477 - acc: 0.8738 - val_loss: 0.3664 - val_acc: 0.8699\n",
      "Epoch 19/48\n",
      "38250/38250 [==============================] - 9s 247us/step - loss: 0.3395 - acc: 0.8739 - val_loss: 0.3578 - val_acc: 0.8764\n",
      "Epoch 20/48\n",
      "38250/38250 [==============================] - 9s 247us/step - loss: 0.3327 - acc: 0.8759 - val_loss: 0.3549 - val_acc: 0.8757\n",
      "Epoch 21/48\n",
      "38250/38250 [==============================] - 9s 246us/step - loss: 0.3230 - acc: 0.8802 - val_loss: 0.3580 - val_acc: 0.8764\n",
      "Epoch 22/48\n",
      "38250/38250 [==============================] - 9s 246us/step - loss: 0.3125 - acc: 0.8807 - val_loss: 0.3529 - val_acc: 0.8748\n",
      "Epoch 23/48\n",
      "38250/38250 [==============================] - 9s 245us/step - loss: 0.3088 - acc: 0.8826 - val_loss: 0.3506 - val_acc: 0.8794\n",
      "Epoch 24/48\n",
      "38250/38250 [==============================] - 9s 244us/step - loss: 0.3011 - acc: 0.8832 - val_loss: 0.3583 - val_acc: 0.8750\n",
      "Epoch 25/48\n",
      "38250/38250 [==============================] - 9s 244us/step - loss: 0.2995 - acc: 0.8848 - val_loss: 0.3533 - val_acc: 0.8779\n",
      "Epoch 26/48\n",
      "38250/38250 [==============================] - 9s 243us/step - loss: 0.2954 - acc: 0.8839 - val_loss: 0.3487 - val_acc: 0.8763\n",
      "Epoch 27/48\n",
      "38250/38250 [==============================] - 9s 243us/step - loss: 0.2945 - acc: 0.8873 - val_loss: 0.3407 - val_acc: 0.8801\n",
      "Epoch 28/48\n",
      "38250/38250 [==============================] - 9s 241us/step - loss: 0.2823 - acc: 0.8898 - val_loss: 0.3459 - val_acc: 0.8799\n",
      "Epoch 29/48\n",
      "38250/38250 [==============================] - 9s 241us/step - loss: 0.2765 - acc: 0.8897 - val_loss: 0.3540 - val_acc: 0.8822\n",
      "Epoch 30/48\n",
      "38250/38250 [==============================] - 9s 240us/step - loss: 0.2770 - acc: 0.8893 - val_loss: 0.3461 - val_acc: 0.8773\n",
      "Epoch 31/48\n",
      "38250/38250 [==============================] - 9s 240us/step - loss: 0.2715 - acc: 0.8915 - val_loss: 0.3511 - val_acc: 0.8830\n",
      "Epoch 32/48\n",
      "38250/38250 [==============================] - 9s 240us/step - loss: 0.2704 - acc: 0.8929 - val_loss: 0.3476 - val_acc: 0.8809\n",
      "Epoch 33/48\n",
      "38250/38250 [==============================] - 9s 243us/step - loss: 0.2645 - acc: 0.8917 - val_loss: 0.3588 - val_acc: 0.8772\n",
      "Epoch 34/48\n",
      "38250/38250 [==============================] - 9s 243us/step - loss: 0.2624 - acc: 0.8936 - val_loss: 0.3657 - val_acc: 0.8782\n",
      "Epoch 35/48\n",
      "38250/38250 [==============================] - 9s 240us/step - loss: 0.2611 - acc: 0.8937 - val_loss: 0.3475 - val_acc: 0.8833\n",
      "Epoch 36/48\n",
      "38250/38250 [==============================] - 9s 241us/step - loss: 0.2556 - acc: 0.8956 - val_loss: 0.3647 - val_acc: 0.8769\n",
      "Epoch 37/48\n",
      "38250/38250 [==============================] - 9s 240us/step - loss: 0.2528 - acc: 0.8965 - val_loss: 0.3526 - val_acc: 0.8806\n",
      "Epoch 38/48\n",
      "38250/38250 [==============================] - 9s 247us/step - loss: 0.2556 - acc: 0.8935 - val_loss: 0.3648 - val_acc: 0.8803\n",
      "Epoch 39/48\n",
      "38250/38250 [==============================] - 9s 246us/step - loss: 0.2484 - acc: 0.8997 - val_loss: 0.3606 - val_acc: 0.8788\n",
      "Epoch 40/48\n",
      "38250/38250 [==============================] - 10s 261us/step - loss: 0.2470 - acc: 0.8979 - val_loss: 0.3637 - val_acc: 0.8784\n",
      "Epoch 41/48\n",
      "38250/38250 [==============================] - 10s 260us/step - loss: 0.2438 - acc: 0.8990 - val_loss: 0.3561 - val_acc: 0.8781\n",
      "Epoch 42/48\n",
      "38250/38250 [==============================] - 10s 265us/step - loss: 0.2413 - acc: 0.8991 - val_loss: 0.3550 - val_acc: 0.8793\n",
      "Epoch 43/48\n",
      "38250/38250 [==============================] - 9s 226us/step - loss: 0.2393 - acc: 0.9005 - val_loss: 0.3627 - val_acc: 0.8764\n",
      "Epoch 44/48\n",
      "38250/38250 [==============================] - 9s 246us/step - loss: 0.2382 - acc: 0.9005 - val_loss: 0.3651 - val_acc: 0.8812\n",
      "Epoch 45/48\n",
      "38250/38250 [==============================] - 9s 243us/step - loss: 0.2356 - acc: 0.9004 - val_loss: 0.3748 - val_acc: 0.8799\n",
      "Epoch 46/48\n",
      "38250/38250 [==============================] - 9s 247us/step - loss: 0.2350 - acc: 0.9008 - val_loss: 0.3700 - val_acc: 0.8816\n",
      "Epoch 47/48\n",
      "38250/38250 [==============================] - 9s 247us/step - loss: 0.2387 - acc: 0.9000 - val_loss: 0.3703 - val_acc: 0.8793\n",
      "Epoch 48/48\n",
      "38250/38250 [==============================] - 9s 243us/step - loss: 0.2308 - acc: 0.9019 - val_loss: 0.3587 - val_acc: 0.8834\n",
      "Test loss: 0.35874681031924704\n",
      "Test accuracy: 0.883407407283783\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, y_train, test_size=0.15, random_state=42)     # validation\n",
    "batch_size = 128\n",
    "epochs = 48\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# add model layers\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1,1), activation='relu', input_shape=(8,8,3)))\n",
    "model.add(Conv2D(128, kernal_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(65, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
